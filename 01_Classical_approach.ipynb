{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project's purpose is to build a machine learning model predicting sentiment of a tweet ragarding COVID-19 pandemic, using both \"classical\" machine learning (like logistic regression ect.) and deep learning methods.\n",
    "\n",
    "The dataset used in this notebook comes from here: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification\n",
    "<br>It was collected and manually tagged by a Kaggle user named Aman Miglani.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "ENGLISH_WORDS = set(words.words())\n",
    "df_train = pd.read_csv(r\"data\\Corona_NLP_train.csv\", encoding='latin1')\n",
    "df_test = pd.read_csv(r\"data\\Corona_NLP_test.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>For corona prevention,we should stop to buy th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "5  As news of the regionÂs first confirmed COVID...            Positive  \n",
       "6  Cashier at grocery store was sharing his insig...            Positive  \n",
       "7  Was at the supermarket today. Didn't buy toile...             Neutral  \n",
       "8  Due to COVID-19 our retail store and classroom...            Positive  \n",
       "9  For corona prevention,we should stop to buy th...            Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset: (41157, 6)\n",
      "Size of the test dataset: (3798, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the train dataset: {}\".format(df_train.shape))\n",
    "print(\"Size of the test dataset: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually three unique sentiment values are just enough, so I will recode the target variable to such shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_sentiment(y):\n",
    "\n",
    "    if y in ['Extremely Positive', 'Positive']:\n",
    "        return 'Positive'\n",
    "    elif y in ['Extremely Negative', 'Negative']:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sentiment'] = df_train['Sentiment'].apply(lambda x: recode_sentiment(x))\n",
    "df_test['Sentiment'] = df_test['Sentiment'].apply(lambda x: recode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>For corona prevention,we should stop to buy th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   Neutral  \n",
       "1  advice Talk to your neighbours family to excha...  Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...  Positive  \n",
       "3  My food stock is not the only one which is emp...  Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Negative  \n",
       "5  As news of the regionÂs first confirmed COVID...  Positive  \n",
       "6  Cashier at grocery store was sharing his insig...  Positive  \n",
       "7  Was at the supermarket today. Didn't buy toile...   Neutral  \n",
       "8  Due to COVID-19 our retail store and classroom...  Positive  \n",
       "9  For corona prevention,we should stop to buy th...  Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cells include cleaning tweets: removing hashtags, URLs, HTML marks, Twitter mentions, stop words and lemmatizing words. </br>\n",
    "\n",
    "Stop words are frequently occuring words which do not bring much information for our algorithms.</br>\n",
    "\n",
    "Lemmatization is a process of transforming a word into its root form, for example: running -> run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(string):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', '', string)\n",
    "\n",
    "def remove_html(string):\n",
    "    return re.sub(r'<.*?>', '', string)\n",
    "\n",
    "def remove_numbers(string):\n",
    "    return re.sub(r'\\d+', '', string)\n",
    "\n",
    "def remove_mentions(string):\n",
    "    return re.sub(r'@\\w+', '', string)\n",
    "\n",
    "def remove_hashtags(string):\n",
    "    return re.sub(r'#\\w+', '', string)\n",
    "\n",
    "def clean_data(tweet, return_tokenized=True):\n",
    "    \n",
    "    # Tokenization\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    cleaned_tweet = []\n",
    "    \n",
    "    for token, tag in pos_tag(tokens):\n",
    "        \n",
    "        # Cleaning tokens with regular expressions\n",
    "        token = remove_url(token)\n",
    "        token = remove_html(token)\n",
    "        token = remove_numbers(token)\n",
    "        token = remove_mentions(token)\n",
    "        token = remove_hashtags(token)\n",
    "        \n",
    "        # Lemmatizing tokens with part of speech recognition\n",
    "        \n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "        \n",
    "        token = token.lower()\n",
    "        \n",
    "        if token not in punctuation and token not in STOPWORDS and token in ENGLISH_WORDS:\n",
    "            cleaned_tweet.append(token)\n",
    "    #TfidfVectorizer accepts strings instead of lists of tokens\n",
    "    if not return_tokenized:\n",
    "        cleaned_tweet = ' '.join([token for token in cleaned_tweet])\n",
    "\n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['OriginalTweet'] = df_train['OriginalTweet'].apply(lambda x: clean_data(x, return_tokenized=False))\n",
    "df_test['OriginalTweet'] = df_test['OriginalTweet'].apply(lambda x: clean_data(x, return_tokenized=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk family exchange phone number creat...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>give elderly disable dedicate shopping hour am...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ready go supermarket outbreak paranoid food st...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>news first confirm covid case come county last...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>cashier grocery store share insight prove cred...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>supermarket today buy toilet paper</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>due covid retail store classroom open business...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>corona prevention stop buy thing cash use paym...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0                                                      Neutral  \n",
       "1  advice talk family exchange phone number creat...  Positive  \n",
       "2  give elderly disable dedicate shopping hour am...  Positive  \n",
       "3  food stock one empty please panic enough food ...  Positive  \n",
       "4  ready go supermarket outbreak paranoid food st...  Negative  \n",
       "5  news first confirm covid case come county last...  Positive  \n",
       "6  cashier grocery store share insight prove cred...  Positive  \n",
       "7                 supermarket today buy toilet paper   Neutral  \n",
       "8  due covid retail store classroom open business...  Positive  \n",
       "9  corona prevention stop buy thing cash use paym...  Negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['NumberOfWords'] = df_train['OriginalTweet'].apply(lambda x: len(x.split()))\n",
    "df_test['NumberOfWords'] = df_test['OriginalTweet'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>NumberOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td></td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk family exchange phone number creat...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>give elderly disable dedicate shopping hour am...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ready go supermarket outbreak paranoid food st...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>news first confirm covid case come county last...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>cashier grocery store share insight prove cred...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>supermarket today buy toilet paper</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>due covid retail store classroom open business...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>corona prevention stop buy thing cash use paym...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  NumberOfWords  \n",
       "0                                                      Neutral              0  \n",
       "1  advice talk family exchange phone number creat...  Positive             22  \n",
       "2  give elderly disable dedicate shopping hour am...  Positive              9  \n",
       "3  food stock one empty please panic enough food ...  Positive             15  \n",
       "4  ready go supermarket outbreak paranoid food st...  Negative             14  \n",
       "5  news first confirm covid case come county last...  Positive             22  \n",
       "6  cashier grocery store share insight prove cred...  Positive             12  \n",
       "7                 supermarket today buy toilet paper   Neutral              5  \n",
       "8  due covid retail store classroom open business...  Positive             20  \n",
       "9  corona prevention stop buy thing cash use paym...  Negative             19  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train['NumberOfWords'] > 0,]\n",
    "df_test = df_test.loc[df_test['NumberOfWords'] > 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>NumberOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk family exchange phone number creat...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>give elderly disable dedicate shopping hour am...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ready go supermarket outbreak paranoid food st...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>news first confirm covid case come county last...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>cashier grocery store share insight prove cred...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>supermarket today buy toilet paper</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>due covid retail store classroom open business...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>corona prevention stop buy thing cash use paym...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3809</td>\n",
       "      <td>48761</td>\n",
       "      <td>Makati, Manila</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>month crowd supermarket restaurant however red...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName                   Location     TweetAt  \\\n",
       "1       3800       48752                         UK  16-03-2020   \n",
       "2       3801       48753                  Vagabonds  16-03-2020   \n",
       "3       3802       48754                        NaN  16-03-2020   \n",
       "4       3803       48755                        NaN  16-03-2020   \n",
       "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7       3806       48758                    Austria  16-03-2020   \n",
       "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "10      3809       48761             Makati, Manila  16-03-2020   \n",
       "\n",
       "                                        OriginalTweet Sentiment  NumberOfWords  \n",
       "1   advice talk family exchange phone number creat...  Positive             22  \n",
       "2   give elderly disable dedicate shopping hour am...  Positive              9  \n",
       "3   food stock one empty please panic enough food ...  Positive             15  \n",
       "4   ready go supermarket outbreak paranoid food st...  Negative             14  \n",
       "5   news first confirm covid case come county last...  Positive             22  \n",
       "6   cashier grocery store share insight prove cred...  Positive             12  \n",
       "7                  supermarket today buy toilet paper   Neutral              5  \n",
       "8   due covid retail store classroom open business...  Positive             20  \n",
       "9   corona prevention stop buy thing cash use paym...  Negative             19  \n",
       "10  month crowd supermarket restaurant however red...   Neutral             16  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train dataset: (41052, 7)\n",
      "Size of the test dataset: (3792, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the train dataset: {}\".format(df_train.shape))\n",
    "print(\"Size of the test dataset: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('NumberOfWords', axis=1, inplace=True)\n",
    "df_test.drop('NumberOfWords', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapping = {'Negative':0, 'Neutral':1, 'Positive':2}\n",
    "df_train['Sentiment'] = df_train['Sentiment'].map(y_mapping).astype('category')\n",
    "df_test['Sentiment'] = df_test['Sentiment'].map(y_mapping).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk family exchange phone number creat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>give elderly disable dedicate shopping hour am...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock one empty please panic enough food ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>ready go supermarket outbreak paranoid food st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>48756</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>news first confirm covid case come county last...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>48757</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>cashier grocery store share insight prove cred...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>48758</td>\n",
       "      <td>Austria</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>supermarket today buy toilet paper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>48759</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>due covid retail store classroom open business...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>48760</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>corona prevention stop buy thing cash use paym...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3809</td>\n",
       "      <td>48761</td>\n",
       "      <td>Makati, Manila</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>month crowd supermarket restaurant however red...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName                   Location     TweetAt  \\\n",
       "1       3800       48752                         UK  16-03-2020   \n",
       "2       3801       48753                  Vagabonds  16-03-2020   \n",
       "3       3802       48754                        NaN  16-03-2020   \n",
       "4       3803       48755                        NaN  16-03-2020   \n",
       "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7       3806       48758                    Austria  16-03-2020   \n",
       "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "10      3809       48761             Makati, Manila  16-03-2020   \n",
       "\n",
       "                                        OriginalTweet Sentiment  \n",
       "1   advice talk family exchange phone number creat...         2  \n",
       "2   give elderly disable dedicate shopping hour am...         2  \n",
       "3   food stock one empty please panic enough food ...         2  \n",
       "4   ready go supermarket outbreak paranoid food st...         0  \n",
       "5   news first confirm covid case come county last...         2  \n",
       "6   cashier grocery store share insight prove cred...         2  \n",
       "7                  supermarket today buy toilet paper         1  \n",
       "8   due covid retail store classroom open business...         2  \n",
       "9   corona prevention stop buy thing cash use paym...         0  \n",
       "10  month crowd supermarket restaurant however red...         1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = df_train['Sentiment'].copy(), df_test['Sentiment'].copy()\n",
    "\n",
    "X_train_org, X_test_org = df_train['OriginalTweet'].copy(), df_test['OriginalTweet'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Next cells include training models and hyperparameter tuning.</br>\n",
    "<br>The tuning involves both TfidfVectorizer and each of the following: logistic regression, multinomial naive Bayes, linear support vector machine.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf_logistic_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__max_features':[100, 200, 300, 400, 600],\n",
    "               'vect__min_df':[5, 7, 9, 11],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__max_features':[100, 200, 300, 400, 600],\n",
    "               'vect__min_df':[5, 7, 9, 11],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "tfidf_logistic_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(encoding='latin1', stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "tfidf_logistic_grid = GridSearchCV(tfidf_logistic_pipeline, param_grid=tdidf_logistic_grid, cv=cv,\n",
    "                                  verbose=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.57173783 0.57173783 0.57173783 0.57178655\n",
      " 0.62252747 0.62247874 0.62245439 0.62238131 0.64703316 0.64708188\n",
      " 0.64708188 0.6471306  0.67292704 0.67346297 0.67307321 0.67300012\n",
      " 0.70547152 0.70573952 0.70537411 0.70554464        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57146988 0.57146988 0.57146988 0.57144552 0.62206473 0.62208909\n",
      " 0.62199165 0.62201601 0.64827543 0.6485434  0.6485434  0.64856776\n",
      " 0.67402322 0.67463221 0.67436427 0.67441297 0.70742023 0.70781\n",
      " 0.70732281 0.70773694        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.57139679 0.57139679\n",
      " 0.57139679 0.57132371 0.6220404  0.62191859 0.62196732 0.62201604\n",
      " 0.64856775 0.64864083 0.64864083 0.64868955 0.67431549 0.67458347\n",
      " 0.67441294 0.67421806 0.70722537 0.70802926 0.70744464 0.70749336\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.57093412 0.57093412 0.57093412 0.57081232\n",
      " 0.62367254 0.62372126 0.62379434 0.62376998 0.65197807 0.6520268\n",
      " 0.6520268  0.65200243 0.67731168 0.67775017 0.67745785 0.67740912\n",
      " 0.71122029 0.71126905 0.71117158 0.71114723        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57115336 0.57115336 0.57115336 0.57093411 0.62372127 0.62384309\n",
      " 0.62384307 0.62381871 0.65139345 0.65151525 0.65151525 0.65153961\n",
      " 0.6771412  0.67748225 0.67740916 0.67726301 0.71092795 0.71107408\n",
      " 0.71100105 0.71102539        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.57110464 0.57110464\n",
      " 0.57110464 0.57090976 0.62369692 0.62381871 0.62372128 0.62374564\n",
      " 0.65149088 0.6515396  0.6515396  0.65163704 0.67716556 0.6774579\n",
      " 0.67736045 0.67731173 0.71102536 0.71124458 0.7110741  0.71090358]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(encoding='latin1',\n",
       "                                                        stop_words='english')),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__max_features': [100, 200, 300, 400, 600],\n",
       "                          'vect__min_df': [5, 7, 9, 11],\n",
       "                          'vect__ngram_range': [(1, 1)]},\n",
       "                         {'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__max_features': [100, 200, 300, 400, 600],\n",
       "                          'vect__min_df': [5, 7, 9, 11],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logistic_grid.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1.0, 'clf__penalty': 'l2', 'vect__max_features': 600, 'vect__min_df': 7, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_logistic_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logistic_pipeline = tfidf_logistic_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(encoding='latin1', max_features=600, min_df=7,\n",
       "                                 norm=None, stop_words='english',\n",
       "                                 use_idf=False)),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logistic_pipeline.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train=X_train_org, X_test=X_test_org, y_train=y_train, y_test=y_test):\n",
    "    \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, preds_train)\n",
    "    test_acc = accuracy_score(y_test, preds_test)\n",
    "    \n",
    "    return {'Train accuracy':train_acc, 'Test accuracy':test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train accuracy': 0.7292214752021826, 'Test accuracy': 0.696993670886076}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model=tfidf_logistic_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73     15392\n",
      "           1       0.57      0.72      0.64      7620\n",
      "           2       0.79      0.76      0.77     18040\n",
      "\n",
      "    accuracy                           0.73     41052\n",
      "   macro avg       0.71      0.73      0.71     41052\n",
      "weighted avg       0.74      0.73      0.73     41052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      1633\n",
      "           1       0.52      0.67      0.58       613\n",
      "           2       0.73      0.73      0.73      1546\n",
      "\n",
      "    accuracy                           0.70      3792\n",
      "   macro avg       0.67      0.69      0.68      3792\n",
      "weighted avg       0.71      0.70      0.70      3792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, tfidf_logistic_pipeline.predict(X_train_org)))\n",
    "print('-'*80)\n",
    "print(classification_report(y_test, tfidf_logistic_pipeline.predict(X_test_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf_naivebayes_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__max_features':[100, 200, 300, 400, 600],\n",
    "               'vect__min_df':[5, 7, 9, 11],\n",
    "               'nb__alpha': np.arange(1, 11, 1)},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__max_features':[100, 200, 300, 400, 600],\n",
    "               'vect__min_df':[5, 7, 9, 11],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'nb__alpha': np.arange(1, 11, 1)},\n",
    "              ]\n",
    "tfidf_naivebayes_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(encoding='latin1', stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "tfidf_naivebayes_grid = GridSearchCV(tfidf_naivebayes_pipeline, param_grid=tdidf_naivebayes_grid, cv=cv,\n",
    "                                  verbose=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(encoding='latin1',\n",
       "                                                        stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'nb__alpha': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                          'vect__max_features': [100, 200, 300, 400, 600],\n",
       "                          'vect__min_df': [5, 7, 9, 11],\n",
       "                          'vect__ngram_range': [(1, 1)]},\n",
       "                         {'nb__alpha': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                          'vect__max_features': [100, 200, 300, 400, 600],\n",
       "                          'vect__min_df': [5, 7, 9, 11],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_naivebayes_grid.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(encoding='latin1', max_features=600, min_df=7,\n",
       "                                 norm=None, stop_words='english',\n",
       "                                 use_idf=False)),\n",
       "                ('nb', MultinomialNB(alpha=1))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_naivebayes_pipeline = tfidf_naivebayes_grid.best_estimator_\n",
    "tfidf_naivebayes_pipeline.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train accuracy': 0.6422829581993569, 'Test accuracy': 0.6220991561181435}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model=tfidf_naivebayes_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67     15392\n",
      "           1       0.46      0.40      0.43      7620\n",
      "           2       0.68      0.73      0.70     18040\n",
      "\n",
      "    accuracy                           0.64     41052\n",
      "   macro avg       0.60      0.60      0.60     41052\n",
      "weighted avg       0.64      0.64      0.64     41052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67      1633\n",
      "           1       0.36      0.34      0.35       613\n",
      "           2       0.65      0.69      0.67      1546\n",
      "\n",
      "    accuracy                           0.62      3792\n",
      "   macro avg       0.57      0.56      0.57      3792\n",
      "weighted avg       0.62      0.62      0.62      3792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, tfidf_naivebayes_pipeline.predict(X_train_org)))\n",
    "print('-'*80)\n",
    "print(classification_report(y_test, tfidf_naivebayes_pipeline.predict(X_test_org)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdidf_svm_grid = {\n",
    "    'svm__penalty': ['l1', 'l2'],\n",
    "    'svm__C': np.arange(1, 11, 1)\n",
    "}\n",
    "tdidf_svm_pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(encoding='latin1', max_features=600, min_df=7,\n",
    "                                 norm=None, stop_words='english',\n",
    "                                 use_idf=False)),\n",
    "    ('svm', LinearSVC())\n",
    "])\n",
    "\n",
    "tdidf_svm_grid = GridSearchCV(tdidf_svm_pipeline, param_grid=tdidf_svm_grid, cv=cv,\n",
    "                                  verbose=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.71102544        nan 0.71117159        nan 0.7111716\n",
      "        nan 0.71122031        nan 0.71131774        nan 0.71119595\n",
      "        nan 0.71131775        nan 0.71175617        nan 0.71080619\n",
      "        nan 0.71012419]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(encoding='latin1',\n",
       "                                                        max_features=600,\n",
       "                                                        min_df=7, norm=None,\n",
       "                                                        stop_words='english',\n",
       "                                                        use_idf=False)),\n",
       "                                       ('svm', LinearSVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'svm__C': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         'svm__penalty': ['l1', 'l2']},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdidf_svm_grid.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mariusz\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(encoding='latin1', max_features=600, min_df=7,\n",
       "                                 norm=None, stop_words='english',\n",
       "                                 use_idf=False)),\n",
       "                ('svm', LinearSVC(C=8))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdidf_svm_pipeline = tdidf_svm_grid.best_estimator_\n",
    "tdidf_svm_pipeline.fit(X_train_org, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train accuracy': 0.7285637727759914, 'Test accuracy': 0.6959388185654009}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model=tdidf_svm_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73     15392\n",
      "           1       0.58      0.69      0.63      7620\n",
      "           2       0.79      0.76      0.77     18040\n",
      "\n",
      "    accuracy                           0.73     41052\n",
      "   macro avg       0.71      0.72      0.71     41052\n",
      "weighted avg       0.74      0.73      0.73     41052\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      1633\n",
      "           1       0.52      0.65      0.58       613\n",
      "           2       0.72      0.74      0.73      1546\n",
      "\n",
      "    accuracy                           0.70      3792\n",
      "   macro avg       0.67      0.69      0.67      3792\n",
      "weighted avg       0.71      0.70      0.70      3792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, tdidf_svm_pipeline.predict(X_train_org)))\n",
    "print('-'*80)\n",
    "print(classification_report(y_test, tdidf_svm_pipeline.predict(X_test_org)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>So far, logistic regression and linear SVM are performing the best.</br>\n",
    "<br>The results are not so bad, but there surely is a space for improvement.</br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
