{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd08151db9aaf32c99dfa88ba6f1da24ff0d6757a3be57e8d4dced916debefd5a3f",
   "display_name": "Python 3.8.6 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This procect's purpose is to build a machine learning model predicting sentiment of a tweet ragarding COVID-19 pandemic, using both \"classical\" machine learning (like logistic regression ect.) and deep learning methods.\n",
    "\n",
    "The dataset used in this notebook comes from here: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification\n",
    "<br>It was collected and manually tagged by a Kaggle user named Aman Miglani.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "ENGLISH_WORDS = set(words.words())\n",
    "df_train = pd.read_csv(r\"data\\Corona_NLP_train.csv\", encoding='latin1')\n",
    "df_test = pd.read_csv(r\"data\\Corona_NLP_test.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "5  As news of the regionÂs first confirmed COVID...            Positive  \n",
       "6  Cashier at grocery store was sharing his insig...            Positive  \n",
       "7  Was at the supermarket today. Didn't buy toile...             Neutral  \n",
       "8  Due to COVID-19 our retail store and classroom...            Positive  \n",
       "9  For corona prevention,we should stop to buy th...            Negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>As news of the regionÂs first confirmed COVID...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>Cashier at grocery store was sharing his insig...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>Was at the supermarket today. Didn't buy toile...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>Due to COVID-19 our retail store and classroom...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>For corona prevention,we should stop to buy th...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of the train dataset: (41157, 6)\nSize of the test dataset: (3798, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the train dataset: {}\".format(df_train.shape))\n",
    "print(\"Size of the test dataset: {}\".format(df_test.shape))"
   ]
  },
  {
   "source": [
    "Usually three unique sentiment values are just enough, so I will recode the target variable to such shape."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_sentiment(y):\n",
    "\n",
    "    if y in ['Extremely Positive', 'Positive']:\n",
    "        return 'Positive'\n",
    "    elif y in ['Extremely Negative', 'Negative']:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sentiment'] = df_train['Sentiment'].apply(lambda x: recode_sentiment(x))\n",
    "df_test['Sentiment'] = df_test['Sentiment'].apply(lambda x: recode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   Neutral  \n",
       "1  advice Talk to your neighbours family to excha...  Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...  Positive  \n",
       "3  My food stock is not the only one which is emp...  Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Negative  \n",
       "5  As news of the regionÂs first confirmed COVID...  Positive  \n",
       "6  Cashier at grocery store was sharing his insig...  Positive  \n",
       "7  Was at the supermarket today. Didn't buy toile...   Neutral  \n",
       "8  Due to COVID-19 our retail store and classroom...  Positive  \n",
       "9  For corona prevention,we should stop to buy th...  Negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>As news of the regionÂs first confirmed COVID...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>Cashier at grocery store was sharing his insig...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>Was at the supermarket today. Didn't buy toile...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>Due to COVID-19 our retail store and classroom...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>For corona prevention,we should stop to buy th...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(string):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', '', string)\n",
    "\n",
    "def remove_html(string):\n",
    "    return re.sub(r'<.*?>', '', string)\n",
    "\n",
    "def remove_numbers(string):\n",
    "    return re.sub(r'\\d+', '', string)\n",
    "\n",
    "def remove_mentions(string):\n",
    "    return re.sub(r'@\\w+', '', string)\n",
    "\n",
    "def remove_hashtags(string):\n",
    "    return re.sub(r'#\\w+', '', string)\n",
    "\n",
    "def clean_data(tweet, return_tokenized=True):\n",
    "    \n",
    "    # Tokenization\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    cleaned_tweet = []\n",
    "    \n",
    "    for token, tag in pos_tag(tokens):\n",
    "        \n",
    "        # Cleaning tokens with regular expressions\n",
    "        token = remove_url(token)\n",
    "        token = remove_html(token)\n",
    "        token = remove_numbers(token)\n",
    "        token = remove_mentions(token)\n",
    "        token = remove_hashtags(token)\n",
    "        \n",
    "        # Lemmatizing tokens with part of speech recognition\n",
    "        \n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "        \n",
    "        token = token.lower()\n",
    "        \n",
    "        if token not in punctuation and token not in STOPWORDS and token in ENGLISH_WORDS:\n",
    "            cleaned_tweet.append(token)\n",
    "    #TfidfVectorizer accepts strings instead of lists of tokens\n",
    "    if not return_tokenized:\n",
    "        cleaned_tweet = ' '.join([token for token in cleaned_tweet])\n",
    "\n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['OriginalTweet'] = df_train['OriginalTweet'].apply(lambda x: clean_data(x, return_tokenized=False))\n",
    "df_test['OriginalTweet'] = df_test['OriginalTweet'].apply(lambda x: clean_data(x, return_tokenized=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  \n",
       "0                                                      Neutral  \n",
       "1  advice talk family exchange phone number creat...  Positive  \n",
       "2  give elderly disable dedicate shopping hour am...  Positive  \n",
       "3  food stock one empty please panic enough food ...  Positive  \n",
       "4  ready go supermarket outbreak paranoid food st...  Negative  \n",
       "5  news first confirm covid case come county last...  Positive  \n",
       "6  cashier grocery store share insight prove cred...  Positive  \n",
       "7                 supermarket today buy toilet paper   Neutral  \n",
       "8  due covid retail store classroom open business...  Positive  \n",
       "9  corona prevention stop buy thing cash use paym...  Negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td></td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice talk family exchange phone number creat...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>give elderly disable dedicate shopping hour am...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>food stock one empty please panic enough food ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>ready go supermarket outbreak paranoid food st...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>news first confirm covid case come county last...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>cashier grocery store share insight prove cred...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>supermarket today buy toilet paper</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>due covid retail store classroom open business...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>corona prevention stop buy thing cash use paym...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['NumberOfWords'] = df_train['OriginalTweet'].apply(lambda x: len(x.split()))\n",
    "df_test['NumberOfWords'] = df_test['OriginalTweet'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName                   Location     TweetAt  \\\n",
       "0      3799       48751                     London  16-03-2020   \n",
       "1      3800       48752                         UK  16-03-2020   \n",
       "2      3801       48753                  Vagabonds  16-03-2020   \n",
       "3      3802       48754                        NaN  16-03-2020   \n",
       "4      3803       48755                        NaN  16-03-2020   \n",
       "5      3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6      3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7      3806       48758                    Austria  16-03-2020   \n",
       "8      3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9      3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet Sentiment  NumberOfWords  \n",
       "0                                                      Neutral              0  \n",
       "1  advice talk family exchange phone number creat...  Positive             22  \n",
       "2  give elderly disable dedicate shopping hour am...  Positive              9  \n",
       "3  food stock one empty please panic enough food ...  Positive             15  \n",
       "4  ready go supermarket outbreak paranoid food st...  Negative             14  \n",
       "5  news first confirm covid case come county last...  Positive             22  \n",
       "6  cashier grocery store share insight prove cred...  Positive             12  \n",
       "7                 supermarket today buy toilet paper   Neutral              5  \n",
       "8  due covid retail store classroom open business...  Positive             20  \n",
       "9  corona prevention stop buy thing cash use paym...  Negative             19  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n      <th>NumberOfWords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td></td>\n      <td>Neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice talk family exchange phone number creat...</td>\n      <td>Positive</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>give elderly disable dedicate shopping hour am...</td>\n      <td>Positive</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>food stock one empty please panic enough food ...</td>\n      <td>Positive</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>ready go supermarket outbreak paranoid food st...</td>\n      <td>Negative</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>news first confirm covid case come county last...</td>\n      <td>Positive</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>cashier grocery store share insight prove cred...</td>\n      <td>Positive</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>supermarket today buy toilet paper</td>\n      <td>Neutral</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>due covid retail store classroom open business...</td>\n      <td>Positive</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>corona prevention stop buy thing cash use paym...</td>\n      <td>Negative</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train['NumberOfWords'] > 0,]\n",
    "df_test = df_test.loc[df_test['NumberOfWords'] > 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    UserName  ScreenName                   Location     TweetAt  \\\n",
       "1       3800       48752                         UK  16-03-2020   \n",
       "2       3801       48753                  Vagabonds  16-03-2020   \n",
       "3       3802       48754                        NaN  16-03-2020   \n",
       "4       3803       48755                        NaN  16-03-2020   \n",
       "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7       3806       48758                    Austria  16-03-2020   \n",
       "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "10      3809       48761             Makati, Manila  16-03-2020   \n",
       "\n",
       "                                        OriginalTweet Sentiment  NumberOfWords  \n",
       "1   advice talk family exchange phone number creat...  Positive             22  \n",
       "2   give elderly disable dedicate shopping hour am...  Positive              9  \n",
       "3   food stock one empty please panic enough food ...  Positive             15  \n",
       "4   ready go supermarket outbreak paranoid food st...  Negative             14  \n",
       "5   news first confirm covid case come county last...  Positive             22  \n",
       "6   cashier grocery store share insight prove cred...  Positive             12  \n",
       "7                  supermarket today buy toilet paper   Neutral              5  \n",
       "8   due covid retail store classroom open business...  Positive             20  \n",
       "9   corona prevention stop buy thing cash use paym...  Negative             19  \n",
       "10  month crowd supermarket restaurant however red...   Neutral             16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n      <th>NumberOfWords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice talk family exchange phone number creat...</td>\n      <td>Positive</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>give elderly disable dedicate shopping hour am...</td>\n      <td>Positive</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>food stock one empty please panic enough food ...</td>\n      <td>Positive</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>ready go supermarket outbreak paranoid food st...</td>\n      <td>Negative</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>news first confirm covid case come county last...</td>\n      <td>Positive</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>cashier grocery store share insight prove cred...</td>\n      <td>Positive</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>supermarket today buy toilet paper</td>\n      <td>Neutral</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>due covid retail store classroom open business...</td>\n      <td>Positive</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>corona prevention stop buy thing cash use paym...</td>\n      <td>Negative</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3809</td>\n      <td>48761</td>\n      <td>Makati, Manila</td>\n      <td>16-03-2020</td>\n      <td>month crowd supermarket restaurant however red...</td>\n      <td>Neutral</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of the train dataset: (41052, 7)\nSize of the test dataset: (3792, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the train dataset: {}\".format(df_train.shape))\n",
    "print(\"Size of the test dataset: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('NumberOfWords', axis=1, inplace=True)\n",
    "df_test.drop('NumberOfWords', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mapping = {'Negative':0, 'Neutral':1, 'Positive':2}\n",
    "df_train['Sentiment'] = df_train['Sentiment'].map(y_mapping).astype('category')\n",
    "df_test['Sentiment'] = df_test['Sentiment'].map(y_mapping).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    UserName  ScreenName                   Location     TweetAt  \\\n",
       "1       3800       48752                         UK  16-03-2020   \n",
       "2       3801       48753                  Vagabonds  16-03-2020   \n",
       "3       3802       48754                        NaN  16-03-2020   \n",
       "4       3803       48755                        NaN  16-03-2020   \n",
       "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
       "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
       "7       3806       48758                    Austria  16-03-2020   \n",
       "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
       "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
       "10      3809       48761             Makati, Manila  16-03-2020   \n",
       "\n",
       "                                        OriginalTweet Sentiment  \n",
       "1   advice talk family exchange phone number creat...         2  \n",
       "2   give elderly disable dedicate shopping hour am...         2  \n",
       "3   food stock one empty please panic enough food ...         2  \n",
       "4   ready go supermarket outbreak paranoid food st...         0  \n",
       "5   news first confirm covid case come county last...         2  \n",
       "6   cashier grocery store share insight prove cred...         2  \n",
       "7                  supermarket today buy toilet paper         1  \n",
       "8   due covid retail store classroom open business...         2  \n",
       "9   corona prevention stop buy thing cash use paym...         0  \n",
       "10  month crowd supermarket restaurant however red...         1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice talk family exchange phone number creat...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>give elderly disable dedicate shopping hour am...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>food stock one empty please panic enough food ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>ready go supermarket outbreak paranoid food st...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3804</td>\n      <td>48756</td>\n      <td>ÃT: 36.319708,-82.363649</td>\n      <td>16-03-2020</td>\n      <td>news first confirm covid case come county last...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3805</td>\n      <td>48757</td>\n      <td>35.926541,-78.753267</td>\n      <td>16-03-2020</td>\n      <td>cashier grocery store share insight prove cred...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3806</td>\n      <td>48758</td>\n      <td>Austria</td>\n      <td>16-03-2020</td>\n      <td>supermarket today buy toilet paper</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3807</td>\n      <td>48759</td>\n      <td>Atlanta, GA USA</td>\n      <td>16-03-2020</td>\n      <td>due covid retail store classroom open business...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3808</td>\n      <td>48760</td>\n      <td>BHAVNAGAR,GUJRAT</td>\n      <td>16-03-2020</td>\n      <td>corona prevention stop buy thing cash use paym...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3809</td>\n      <td>48761</td>\n      <td>Makati, Manila</td>\n      <td>16-03-2020</td>\n      <td>month crowd supermarket restaurant however red...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = df_train['Sentiment'].copy(), df_test['Sentiment'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(encoding='latin1', stop_words='english', min_df=5, max_features=200)\n",
    "X_train_tfidf = vectorizer.fit_transform(df_train['OriginalTweet'])\n",
    "X_test_tfidf = vectorizer.transform(df_test['OriginalTweet'])\n",
    "X_train_tfidf = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "X_test_tfidf = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_tr, X_val, y_tr=y_train, y_val=y_test):\n",
    "    \n",
    "    train_accuracy = accuracy_score( y_tr, model.predict(X_tr) )\n",
    "    valid_accuracy = accuracy_score( y_val, model.predict(X_val) )\n",
    "    \n",
    "    return {'Train accuracy': train_accuracy, 'Validation accuracy': valid_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "naive_bayes = MultinomialNB()\n",
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for model in (logistic, naive_bayes, forest):\n",
    "    model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------\n",
      "LogisticRegression\n",
      "{'Train accuracy': 0.6339764201500536, 'Validation accuracy': 0.6215717299578059}\n",
      "\n",
      "----------------------------------------\n",
      "MultinomialNB\n",
      "{'Train accuracy': 0.586987235701062, 'Validation accuracy': 0.5851793248945147}\n",
      "\n",
      "----------------------------------------\n",
      "RandomForestClassifier\n",
      "{'Train accuracy': 0.9425850141284224, 'Validation accuracy': 0.5970464135021097}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in (logistic, naive_bayes, forest):\n",
    "    print('-'*40)\n",
    "    print(model.__class__.__name__)\n",
    "    print(evaluate_model(model=model, X_tr=X_train_tfidf, X_val=X_test_tfidf))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "random_forest_grid = {\n",
    "    'n_estimators':[100, 200, 300],\n",
    "    'max_depth':np.arange(5, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=100; total time=   2.3s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=100; total time=   2.5s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=100; total time=   2.6s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=100; total time=   2.4s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=100; total time=   2.4s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=200; total time=   4.8s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=200; total time=   4.7s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=200; total time=   4.7s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=200; total time=   4.7s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=200; total time=   4.8s\n",
      "[CV 1/5] END ..................max_depth=5, n_estimators=300; total time=   7.1s\n",
      "[CV 2/5] END ..................max_depth=5, n_estimators=300; total time=   7.1s\n",
      "[CV 3/5] END ..................max_depth=5, n_estimators=300; total time=   7.1s\n",
      "[CV 4/5] END ..................max_depth=5, n_estimators=300; total time=   7.1s\n",
      "[CV 5/5] END ..................max_depth=5, n_estimators=300; total time=   7.1s\n",
      "[CV 1/5] END ..................max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV 2/5] END ..................max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV 3/5] END ..................max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV 4/5] END ..................max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV 5/5] END ..................max_depth=6, n_estimators=100; total time=   2.7s\n",
      "[CV 1/5] END ..................max_depth=6, n_estimators=200; total time=   5.4s\n",
      "[CV 2/5] END ..................max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV 3/5] END ..................max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV 4/5] END ..................max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV 5/5] END ..................max_depth=6, n_estimators=200; total time=   5.5s\n",
      "[CV 1/5] END ..................max_depth=6, n_estimators=300; total time=   8.4s\n",
      "[CV 2/5] END ..................max_depth=6, n_estimators=300; total time=   8.3s\n",
      "[CV 3/5] END ..................max_depth=6, n_estimators=300; total time=   8.6s\n",
      "[CV 4/5] END ..................max_depth=6, n_estimators=300; total time=   8.3s\n",
      "[CV 5/5] END ..................max_depth=6, n_estimators=300; total time=   8.3s\n",
      "[CV 1/5] END ..................max_depth=7, n_estimators=100; total time=   3.1s\n",
      "[CV 2/5] END ..................max_depth=7, n_estimators=100; total time=   3.1s\n",
      "[CV 3/5] END ..................max_depth=7, n_estimators=100; total time=   3.1s\n",
      "[CV 4/5] END ..................max_depth=7, n_estimators=100; total time=   3.1s\n",
      "[CV 5/5] END ..................max_depth=7, n_estimators=100; total time=   3.0s\n",
      "[CV 1/5] END ..................max_depth=7, n_estimators=200; total time=   6.5s\n",
      "[CV 2/5] END ..................max_depth=7, n_estimators=200; total time=   7.4s\n",
      "[CV 3/5] END ..................max_depth=7, n_estimators=200; total time=   6.3s\n",
      "[CV 4/5] END ..................max_depth=7, n_estimators=200; total time=   6.2s\n",
      "[CV 5/5] END ..................max_depth=7, n_estimators=200; total time=   6.2s\n",
      "[CV 1/5] END ..................max_depth=7, n_estimators=300; total time=   9.6s\n",
      "[CV 2/5] END ..................max_depth=7, n_estimators=300; total time=   9.5s\n",
      "[CV 3/5] END ..................max_depth=7, n_estimators=300; total time=   9.5s\n",
      "[CV 4/5] END ..................max_depth=7, n_estimators=300; total time=   9.6s\n",
      "[CV 5/5] END ..................max_depth=7, n_estimators=300; total time=   9.4s\n",
      "[CV 1/5] END ..................max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV 2/5] END ..................max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV 3/5] END ..................max_depth=8, n_estimators=100; total time=   3.4s\n",
      "[CV 4/5] END ..................max_depth=8, n_estimators=100; total time=   3.4s\n",
      "[CV 5/5] END ..................max_depth=8, n_estimators=100; total time=   3.5s\n",
      "[CV 1/5] END ..................max_depth=8, n_estimators=200; total time=   7.0s\n",
      "[CV 2/5] END ..................max_depth=8, n_estimators=200; total time=   7.0s\n",
      "[CV 3/5] END ..................max_depth=8, n_estimators=200; total time=   7.0s\n",
      "[CV 4/5] END ..................max_depth=8, n_estimators=200; total time=   7.0s\n",
      "[CV 5/5] END ..................max_depth=8, n_estimators=200; total time=   7.0s\n",
      "[CV 1/5] END ..................max_depth=8, n_estimators=300; total time=  10.5s\n",
      "[CV 2/5] END ..................max_depth=8, n_estimators=300; total time=  10.5s\n",
      "[CV 3/5] END ..................max_depth=8, n_estimators=300; total time=  10.8s\n",
      "[CV 4/5] END ..................max_depth=8, n_estimators=300; total time=  10.4s\n",
      "[CV 5/5] END ..................max_depth=8, n_estimators=300; total time=  11.4s\n",
      "[CV 1/5] END ..................max_depth=9, n_estimators=100; total time=   3.9s\n",
      "[CV 2/5] END ..................max_depth=9, n_estimators=100; total time=   4.0s\n",
      "[CV 3/5] END ..................max_depth=9, n_estimators=100; total time=   4.0s\n",
      "[CV 4/5] END ..................max_depth=9, n_estimators=100; total time=   4.1s\n",
      "[CV 5/5] END ..................max_depth=9, n_estimators=100; total time=   4.0s\n",
      "[CV 1/5] END ..................max_depth=9, n_estimators=200; total time=   7.9s\n",
      "[CV 2/5] END ..................max_depth=9, n_estimators=200; total time=   8.0s\n",
      "[CV 3/5] END ..................max_depth=9, n_estimators=200; total time=   8.1s\n",
      "[CV 4/5] END ..................max_depth=9, n_estimators=200; total time=   8.3s\n",
      "[CV 5/5] END ..................max_depth=9, n_estimators=200; total time=   7.8s\n",
      "[CV 1/5] END ..................max_depth=9, n_estimators=300; total time=  11.7s\n",
      "[CV 2/5] END ..................max_depth=9, n_estimators=300; total time=  11.6s\n",
      "[CV 3/5] END ..................max_depth=9, n_estimators=300; total time=  11.8s\n",
      "[CV 4/5] END ..................max_depth=9, n_estimators=300; total time=  11.7s\n",
      "[CV 5/5] END ..................max_depth=9, n_estimators=300; total time=  11.8s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': array([5, 6, 7, 8, 9]),\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy', verbose=5)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier()\n",
    "forest_tune = GridSearchCV(forest2, cv=cv, param_grid=random_forest_grid,\n",
    "scoring='accuracy', verbose=5)\n",
    "\n",
    "forest_tune.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Train accuracy': 0.5709587839812921, 'Validation accuracy': 0.5485232067510548}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model=forest_tune, X_tr=X_train_tfidf, X_val=X_test_tfidf))"
   ]
  },
  {
   "source": [
    "The results aren't satisfying. Trying diffrent data preprocessing and vectorizing strategies is necessary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}